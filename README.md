# CPRet: A Dataset, Benchmark, and Model for Retrieval in Competitive Programming

**[Hugging Face Collection](https://huggingface.co/collections/coldchair16/cpret-682451276f05c5988fcbdf34)**
**[arXiv Paper (coming soon)](#)**

## üìå Overview

**CPRet** is a comprehensive suite for competitive programming retrieval research, consisting of:

* A large-scale dataset and benchmark for retrieval tasks in coding contests.
* A dual-stage training pipeline with contrastive pretraining and task-specific fine-tuning.
* A local retrieval server for **simplified description** and **duplicate problem** search, powered by our trained model **CPRet-Prob** (based on [Salesforce/SFR-Embedding-Code-2B_R](https://huggingface.co/Salesforce/SFR-Embedding-Code-2B_R)).

We target four retrieval tasks specifically designed for competitive programming, enabling both practical applications (e.g., search, deduplication) and academic benchmarking.

---

## üåê Try Online Demo

We provide an **online demo** of the CPRet retrieval service, available at:

üëâ [http://1.94.255.218:5000/](http://1.94.255.218:5000/)

This demo supports both **duplicate problem detection** and **simplified description retrieval**.  
It runs the same codebase and embedding model as the local deployment (see below), so you can preview its capabilities before setting up your own instance.

## üß∞ Repository Contents

* `cp-retrieval-server/`: Code for running a local retrieval web service.
* `stage1/`: Code for stage-1 contrastive pretraining.
* `stage2/`: Code for stage-2 problem-level fine-tuning.

---

## ‚öôÔ∏è Setup

### Environment

* Recommended: `python >= 3.10`

* Install dependencies:

  ```bash
  pip install -r requirements.txt
  ```

* Install PyTorch (with CUDA support if needed):
  ‚Üí Refer to: [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)

* PyTorch ‚â• 2.0 is recommended.

### üîÅ Accessing Hugging Face from Restricted Regions

If you're experiencing connectivity issues with Hugging Face, consider using the official mirror:

```python
import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
```

Or set it as an environment variable:

```bash
export HF_ENDPOINT=https://hf-mirror.com
```

---

## üöÄ Run Local Retrieval Service

1. **Download embeddings:**

   * From: [HF dataset CPRet-Embeddings](https://huggingface.co/datasets/coldchair16/CPRet-Embeddings)
   * Download the following files into `cp-retrieval-server/`:

     * `probs_embs.npy`
     * `probs.jsonl`

2. **Start the service:**

   ```bash
   cd cp-retrieval-server
   python app.py
   ```

3. **About the Dataset:**

   The current dataset includes problems from the following online judges:

   * [Codeforces](https://codeforces.com/)
   * [AtCoder](https://atcoder.jp/)
   * [SPOJ](https://www.spoj.com/)
   * [Nowcoder](https://ac.nowcoder.com/)
   * [Luogu](https://www.luogu.com.cn/)
   * [Loj](https://loj.ac/)

   The data is collected up to **May 2025**.
   You can add your own data source and generate embeddings using [`compute_embs.py`](cp-retrieval-server/compute_embs.py).
   If you have access to a larger or more diverse problem dataset, **we welcome contributions and are happy to update the collection** ‚Äî feel free to contact us (231775009@qq.com) or open an issue/pull request.

4. **System Requirements:**

   This service can be run on **CPU** or **GPU**, depending on your environment.
   We recommend at least **16GB of system memory or GPU VRAM** for smooth operation.

   * On **CPU** (8 cores): typical query latency is **10‚Äì20 seconds**.
   * On **GPU** (e.g., A800): typical query latency is **0.1‚Äì1 seconds**.

---

## üèãÔ∏è‚Äç‚ôÄÔ∏è Training Instructions

> **‚ö†Ô∏è Note**: Recommended GPU memory ‚â• **50 GB** to avoid OOM.

Here's the updated `README.md` section in **English**, incorporating:

* Instructions for Stage 1 training;
* A clear warning and fix for using `Salesforce/SFR-Embedding-Code-2B_R` with `device_map="auto"`;
* A link to your patched `modeling_gemma2.py`.

---

## üîß Stage 1: Contrastive Pretraining

```bash
cd stage1
torchrun --nproc_per_node=8 train.py
````

* Change `--nproc_per_node` to match the number of available GPUs.
* Use `--help` to see all configurable hyperparameters.

### ‚ö†Ô∏è Note on Using `Salesforce/SFR-Embedding-Code-2B_R`

If you are using [`Salesforce/SFR-Embedding-Code-2B_R`](https://huggingface.co/Salesforce/SFR-Embedding-Code-2B_R) as your encoder, make sure to **manually disable `device_map="auto"`** when loading the model.

The original code might look like this:

```python
self.model = Gemma2Model.from_pretrained(config._name_or_path, trust_remote_code=True, is_causal=False, device_map="auto")
self.tokenizer = AutoTokenizer.from_pretrained(config._name_or_path, trust_remote_code=True, device_map="auto")
```

This setting can cause the model to skip training due to automatic device placement.
**Please change it to:**

```python
self.model = Gemma2Model.from_pretrained(config._name_or_path, trust_remote_code=True, is_causal=False, device_map=None)
self.tokenizer = AutoTokenizer.from_pretrained(config._name_or_path, trust_remote_code=True, device_map=None)
```

Alternatively, you can directly copy the patched file from our repo:
üëâ [modeling\_gemma2.py](https://huggingface.co/coldchair16/CPRetriever-Code/blob/main/modeling_gemma2.py)


---
### Stage 2: Problem-Level Fine-Tuning

```bash
cd stage2
torchrun --nproc_per_node=1 train.py
```

* Also supports `--help` to inspect all args.

---

## üîß Notable Hyperparameters

* `--model_path`: Can be either an HF model repo (e.g. `coldchair16/CPRetriever-Code`) or a local directory supporting SentenceTransformer.
* `--eval_only True`: Run evaluation without training.

---

## üì´ Citation & License

* Citation information and license will be released along with the paper.
